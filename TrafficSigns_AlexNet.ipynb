{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cRLfPpAgLL8",
        "outputId": "c17938e5-e750-4991-bee8-0f0b80c54985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Set image size\n",
        "img_size = 224\n",
        "\n",
        "# Define data directories\n",
        "train_data_dir = '/content/drive/MyDrive/trafficsigns/train'\n",
        "val_data_dir = '/content/drive/MyDrive/trafficsigns/test'\n",
        "\n",
        "# Augment the data\n",
        "datagen = ImageDataGenerator(\n",
        "        samplewise_center=True,  # set each sample mean to 0\n",
        "        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.3, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True) # randomnly flip images\n",
        "\n",
        "# Generate training data\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Generate validation data\n",
        "val_generator = datagen.flow_from_directory(\n",
        "        val_data_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (11,11), strides=(4,4), padding='valid', input_shape=(img_size,img_size,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, (5,5), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(384, (3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(384, (3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, (3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(85))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//batch_size,\n",
        "        epochs=10,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=val_generator.samples//batch_size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WS95kLviD8Q",
        "outputId": "58a4536c-98fa-4b8f-e931-f3d3e8c0bbe5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4438 images belonging to 85 classes.\n",
            "Found 1288 images belonging to 85 classes.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 54, 54, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 26, 26, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 26, 26, 96)       384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 26, 26, 256)       614656    \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 26, 26, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 12, 12, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 12, 12, 384)       885120    \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 12, 12, 384)       0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 12, 12, 384)      1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 12, 12, 384)       1327488   \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 12, 12, 384)       0         \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 12, 12, 384)      1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 12, 12, 256)       884992    \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 5, 5, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4096)              26218496  \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 85)                348245    \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 85)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47,133,525\n",
            "Trainable params: 47,114,389\n",
            "Non-trainable params: 19,136\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "138/138 [==============================] - 2733s 19s/step - loss: 3.9680 - accuracy: 0.2158 - val_loss: 28.1957 - val_accuracy: 0.1391\n",
            "Epoch 2/10\n",
            "138/138 [==============================] - 1096s 8s/step - loss: 3.3619 - accuracy: 0.2930 - val_loss: 9.3130 - val_accuracy: 0.1734\n",
            "Epoch 3/10\n",
            "138/138 [==============================] - 1036s 7s/step - loss: 3.0488 - accuracy: 0.3232 - val_loss: 3.6119 - val_accuracy: 0.3422\n",
            "Epoch 4/10\n",
            "138/138 [==============================] - 1031s 7s/step - loss: 2.6982 - accuracy: 0.3627 - val_loss: 4.0485 - val_accuracy: 0.3133\n",
            "Epoch 5/10\n",
            "138/138 [==============================] - 1025s 7s/step - loss: 2.5573 - accuracy: 0.3842 - val_loss: 3.2378 - val_accuracy: 0.4109\n",
            "Epoch 6/10\n",
            "138/138 [==============================] - 1027s 7s/step - loss: 2.4311 - accuracy: 0.4074 - val_loss: 2.8777 - val_accuracy: 0.4008\n",
            "Epoch 7/10\n",
            "138/138 [==============================] - 1083s 8s/step - loss: 2.2087 - accuracy: 0.4401 - val_loss: 2.3724 - val_accuracy: 0.4531\n",
            "Epoch 8/10\n",
            "138/138 [==============================] - 1091s 8s/step - loss: 2.1623 - accuracy: 0.4369 - val_loss: 2.4486 - val_accuracy: 0.4234\n",
            "Epoch 9/10\n",
            "138/138 [==============================] - 1033s 7s/step - loss: 2.0096 - accuracy: 0.4689 - val_loss: 2.4004 - val_accuracy: 0.4633\n",
            "Epoch 10/10\n",
            "138/138 [==============================] - 1039s 8s/step - loss: 1.9897 - accuracy: 0.4725 - val_loss: 1.8492 - val_accuracy: 0.5070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//batch_size,\n",
        "        epochs=20,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=val_generator.samples//batch_size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK8Wr2VrqdeS",
        "outputId": "ec347618-ce1b-4017-abf8-dbf336d8b220"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "138/138 [==============================] - 1028s 7s/step - loss: 1.8686 - accuracy: 0.4911 - val_loss: 1.9965 - val_accuracy: 0.5227\n",
            "Epoch 2/20\n",
            "138/138 [==============================] - 1039s 8s/step - loss: 1.7937 - accuracy: 0.5086 - val_loss: 1.5100 - val_accuracy: 0.5703\n",
            "Epoch 3/20\n",
            "138/138 [==============================] - 1095s 8s/step - loss: 1.6562 - accuracy: 0.5350 - val_loss: 1.6054 - val_accuracy: 0.5719\n",
            "Epoch 4/20\n",
            "138/138 [==============================] - 1026s 7s/step - loss: 1.6860 - accuracy: 0.5447 - val_loss: 1.6723 - val_accuracy: 0.5836\n",
            "Epoch 5/20\n",
            "138/138 [==============================] - 1079s 8s/step - loss: 1.5612 - accuracy: 0.5683 - val_loss: 1.4594 - val_accuracy: 0.6086\n",
            "Epoch 6/20\n",
            "138/138 [==============================] - 1096s 8s/step - loss: 1.5046 - accuracy: 0.5765 - val_loss: 1.4735 - val_accuracy: 0.6031\n",
            "Epoch 7/20\n",
            "138/138 [==============================] - 1028s 7s/step - loss: 1.5080 - accuracy: 0.5772 - val_loss: 1.5769 - val_accuracy: 0.6086\n",
            "Epoch 8/20\n",
            "138/138 [==============================] - 1037s 8s/step - loss: 1.4044 - accuracy: 0.5992 - val_loss: 1.3733 - val_accuracy: 0.6219\n",
            "Epoch 9/20\n",
            "138/138 [==============================] - 1045s 8s/step - loss: 1.3757 - accuracy: 0.6033 - val_loss: 1.4135 - val_accuracy: 0.6328\n",
            "Epoch 10/20\n",
            "138/138 [==============================] - 1037s 8s/step - loss: 1.4218 - accuracy: 0.5917 - val_loss: 1.4171 - val_accuracy: 0.6297\n",
            "Epoch 11/20\n",
            "138/138 [==============================] - 1034s 7s/step - loss: 1.4022 - accuracy: 0.6133 - val_loss: 1.3772 - val_accuracy: 0.6328\n",
            "Epoch 12/20\n",
            "138/138 [==============================] - 1102s 8s/step - loss: 1.3450 - accuracy: 0.6189 - val_loss: 1.4342 - val_accuracy: 0.6266\n",
            "Epoch 13/20\n",
            "138/138 [==============================] - 1110s 8s/step - loss: 1.3268 - accuracy: 0.6205 - val_loss: 1.4946 - val_accuracy: 0.6133\n",
            "Epoch 14/20\n",
            "138/138 [==============================] - 1105s 8s/step - loss: 1.2749 - accuracy: 0.6316 - val_loss: 1.3061 - val_accuracy: 0.6508\n",
            "Epoch 15/20\n",
            "138/138 [==============================] - 1035s 7s/step - loss: 1.2303 - accuracy: 0.6462 - val_loss: 1.3374 - val_accuracy: 0.6492\n",
            "Epoch 16/20\n",
            "138/138 [==============================] - 1104s 8s/step - loss: 1.3264 - accuracy: 0.6335 - val_loss: 1.2657 - val_accuracy: 0.6750\n",
            "Epoch 17/20\n",
            "138/138 [==============================] - 1039s 8s/step - loss: 1.2171 - accuracy: 0.6430 - val_loss: 1.2794 - val_accuracy: 0.6734\n",
            "Epoch 18/20\n",
            "138/138 [==============================] - 1035s 7s/step - loss: 1.1725 - accuracy: 0.6729 - val_loss: 1.0638 - val_accuracy: 0.7102\n",
            "Epoch 19/20\n",
            "138/138 [==============================] - 1053s 8s/step - loss: 1.2797 - accuracy: 0.6387 - val_loss: 1.4582 - val_accuracy: 0.6117\n",
            "Epoch 20/20\n",
            "138/138 [==============================] - 1095s 8s/step - loss: 1.2547 - accuracy: 0.6394 - val_loss: 1.4249 - val_accuracy: 0.6687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "       "
      ],
      "metadata": {
        "id": "pNS3Zl0wjXBy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}